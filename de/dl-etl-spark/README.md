
# Структура данных
 - hdfs:///user/egrep/geo/data - обновляемые данные из "источников"
 - hdfs:///user/egrep/geo/mart - аналитика/витрины
 - hdfs:///user/egrep/geo/sandbox - любая иная работа с данными (в работе не используется)

Данные по городам из csv-файла загружены однократно (в соответствие с требованием) в hdfs:///user/egrep/geo/data/cities

# Инструменты (/src/submitters)
 - [remote-submitter.sh](/de/dl-etl-spark/src/submitters/remote-submitter.sh) - обертка для запуска job в облачной среде
 - submit-*.sh - запуск job через spark-submit в облачной среде, требует наличия .env-файла с переменными среды:
   - IP - ip-адрес host-машины, через которую ведется работа с кластером SPARK
   - USER - пользователь, на хост-машине, от имени которого можно подклбчиться по ssh
   - USER_KEY - файл с private-ключом пользователя USER, для которого настроена ключевая аутентификация на host-машине

Фактически, на driver-узле все данные из папок /src/ и /dags/ копируются и запускаются
из смонтированной папки /lessons/dags/, что позволяет переиспользовать /src/scripts/lib
и сфокусироваться на написании кода приложений без "излишней обвязки", а затем - "прозрачно"
вызывать эти приложения через DAG через SparkSubmitOperator

# Код приложений и DAG-а 
  - приложения: [/src/scripts](/de/dl-etl-spark/src/scripts)
  - общие (для приложений и DAG-а) библиотеки: [/src/srcipts/lib](/de/dl-etl-spark/src/scripts/lib)
  - DAGs: [/src/dags](/de/dl-etl-spark/src/dags)

## 1. Подготовка
- С целью корректной работы с временными зонами, оригинальный файл geo.csv дополнен сведениями о 
временных зонах (geotz.csv)и выполнена соответствующая (однократная) перекладка dataframe в parquet
- в рамках DAG run первым в цепочке всегда идет запуск приложения data_events.py, 
которое обновляет в /data/events обогащенными данными (название города, временная зона)
все события за эту дату в соответствие с {{ ds }}

## 2. Витрина в разрезе пользователей
- формируется приложением mart_user.py
- имеет три входных параметра:
  - дата, от которой ведется отсчет
  - число дней, которые необходимо просмотреть "в глубину" поисках в 
  целях поиска последнего события по пользователю от даты отсчета;
  - число дней (с непрерывной генерацией событий), на основании которого
  осуществляется поиск "домашнего города" (от даты отсчета)
  - итоговые данные кладутся в partition-formatted папку для обеспечения возможности
  легко считать данные впоследствии за любой период

## 3. Витрина в разрезе зон
- формируется приложением mart_geo.py
- требует на вход текущую дату, от которой считает все необходимое
- итоговые данные кладутся в partition-formatted папку для обеспечения возможности
  легко считать данные впоследствии за любой период

## 4. Витрина рекомендации друзей
- формируется приложением mart_friends.py
- требует на вход текущую дату
- использует весь объем данных (events) для расчета на дату
- итоговые данные кладутся в partition-formatted папку для обеспечения возможности
  легко считать данные впоследствии за любой период

## 5. Автоматизация через DAG
- переиспользует общую библиотеку для env
- запускает приложения через SSO
 
